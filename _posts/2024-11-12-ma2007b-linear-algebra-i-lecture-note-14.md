---
id: 13cd3176-005d-80de-af18-c6c11de3cfca
layout: post
date: 2024-11-12
title: MA2007B Linear Algebra I Lecture Note 14
subtitle: 
comments: false
leftToc: false
rightToc: false
sagecell: 
tags: []
categories: [post]

---

## Basis and dimension


Constructing a basis, as introduced in the previous lecture, can be challenging to analyze if the process never ends. While vector spaces can have infinite bases, we'll focus on those with finite bases in this course. However, rather than assuming all vector spaces in our discussion have finite bases, we might adopt the weaker assumption that they are finitely generated. This approach is preferable because assuming a finite basis is a stronger condition than assuming finite generation, and we generally aim to start with the weaker assumption.


We should immediately define the basis for a vector space, as we've already begun to use this term.


**Definition.** A basis $\beta$ for a vector space $V$ is a linearly independent subset of $V$ that generates $V$. If $\beta$ is a basis for $V$, we shall often say that the elements of $\beta$ form a basis for $V$.


**Example.** The standard basis for $F^n$ is the set $\set{(1,0,\ldots,0),(0,1,\ldots, 0),\ldots,(0,0,\ldots, 1)}$.
**Example.**$\set{(1,1,0),(0,1,1),(1,0,1)}$ forms a basis for $\mathbb{R}^3$.


**Example.** $P_n(F)$ has a basis $\set{1,x,x^2,\ldots,x^n}$.


**Example.** $P(F)$ has a basis $\set{1,x,x^2.\ldots}$.


**Lemma.** Let $S\subseteq V$ be a finite set that generates the vector space $V$. Then $V$ has a finite basis.


**proof.** Let's use the following process to construct a basis from $S=\set{x_1,\ldots,x_n}$. 


```markup
S={x_1,...,x_n}
For i in (1,2,...,n)
  if x_i is in span(S\{x_i})
    remove x_i from S
return S
```


Since the elements that were removed are generated by other elements, the above algorithm returns a set that generates the vector space $V$. The elements remaining in the set satisfy $x\notin\text{span}(S\setminus\set{x} )$. Therefore, if the resulting $S=\set{x_1,\ldots,x_n}$ is linearly dependent, then there exist $a_1,\ldots,a_n\in F$, not all zero, such that


$$
0=a_1x_1+\cdots+a_nx_n
$$


Without loss of generality, we may assume $a_1=1$. Thus, $x_1$ is a linear combination of the other elements, which contradicts the property of $S$. Therefore, $S$ is linearly independent and, consequently, a basis.


---


**Lemma.** Let $V$ be a vector space, and let $\beta $ be a basis for $V$. If $S$ is a finite set for $V$ with $\#S>\#\beta$, then $S$ is linearly dependent.


**Proof:** Let $S=\set{y_1,\ldots,y_m}$ and $\beta=\set{x_1,\ldots,x_n}$, where $m>n$. Since $\beta$ is a basis for V, each $y_i$ can be expressed as a linear combination of the basis elements. That is, for each $y_i$, there exist scalars $a_{i1},\ldots,a_{in}\in F$ such that


$$
y_i=a_{i1}x_1+\cdots+a_{in}x_n
$$


Let's consider the $m \times n$ matrix $A = (a_{ij})$. Since $m > n$, $A$ can be reduced to a triangular system through Gaussian elimination, resulting in a zero row vector at the bottom. This implies that $S$ is linearly dependent.


---


**Lemma.** Let $V$ be a vector space having a basis $\beta$ containing exactly $n$ elements. Let $S=\set{y_1,\ldots, y_m}$ be a linearly independent subset of $V$ containing exactly $m$ elements, where $m\leq n$. Then there exists a subset $S_1$ of $\beta$ containing exactly $n-m$ elements such that $S\cup S_1$ generates $V$.


**Proof.** We proceed by induction. The statement is trivially true if $S$ is empty. For the inductive step, we assume the statement holds when $\#S=m\leq n$. We may assume $\# S<n$; if $\#S=n$, then $S$ adjoining another element would become linearly dependent, so $S$ is already a basis. Now, we need to show that the statement holds when $\#S=m+1$. Let $S=\set{y_1,\ldots,y_m,y_{m+1}}$. By the induction hypothesis, there exists $\set{x_1,\ldots,x_k}\subseteq \beta$ where $k=n-m$ such that $\set{y_1,\ldots,y_m,x_1,\ldots,x_k}$ is a basis. Furthermore, there exist scalars $a_1,\ldots, a_m,b_1,\ldots,b_k\in F$ such that


$$
y_{n+1}=a_1y_1+\cdots+a_ny_n+b_1x_1+\cdots+b_kx_k.
$$


Note that $b_1,\ldots, b_k$ are not all zero. Otherwise, $y_{n+1}$ would be a linear combination of $y_1,\ldots,y_n$, contradicting the linear independence of $S$. Without loss of generality, we may assume $b_k\neq 0$. This implies


$$
x_k=\frac{-a_1}{b_k}y_1+\cdots+\frac{-a_n}{b_k}y_n+\frac{1}{b_k}y_{n+1}+\frac{-b_1}{b_k}x_1+\cdots+\frac{-b_{k-1}}{b_k}x_{k-1},
$$


Thus, $\set{y_1,\ldots,y_{k+1},x_1,\ldots, x_{k-1}}$ generates the vector space. We can therefore conclude that the statement holds by induction.

